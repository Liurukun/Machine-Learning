[
  {
    "path": "models/2023-10-17-one-shot-learning-with-r/",
    "title": "Lesson 6: One Shot Learning with R",
    "description": "One-shot learning is a machine learning algorithm using a limited amount of training set data to compare the similarities and differences between two images. This section will introduce you touUse R keras for building self define generator, building self define layer, building self define backend function.",
    "author": [],
    "date": "2023-10-18",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nExample 1: Recognization of mnist number\r\n\r\nExample 1: Recognization of mnist number\r\nStep 1 : Data Load\r\nRead Data and Split into train、validate and test\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-10-18T00:21:01+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-advanced-machine-learning/",
    "title": "Lesson 2: Advanced Machine Learning",
    "description": "Welcome to the introduction to Deep Learning! Using Keras and Tensorflow, you'll learn how to: 1) create a fully-connected neural network architecture, 2) apply neural nets to regression and classification, 3) train neural nets with stochastic gradient descent, and 4) improve performance with dropout, batch normalization, and other techniques.",
    "author": [],
    "date": "2023-10-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Deep learning and its application to ecology\r\n2. Deep learning including fully-connected neural networks\r\n3. Training neutral network models\r\n4. Improving the performance of network models\r\n5. Setup R environment for deeep learning\r\n\r\n1. Deep learning and its application to ecology\r\n1.1 Artificial neural networks and deep learning\r\nArtificial neural networks are a class of machine learning algorithms that are loosely based on biological neural networks. Advances in the availability of high performance computers allow neural networks to be larger and deeper. Deep learning is a subfield of machine learning primarily concerned with these deep neural networks.\r\nsingle_layer perception\r\n\r\nMultilayer perception\r\nMLPs (multilayer perceptron) traditionally comprise at least 3 layers: an input layer, a hidden layer, and an output layer.\r\n\r\nDeep learning\r\nMLPs often comprise many more layers, allowing them to solve more complex problems. Much of the recent focus has been concentrated in the subfield of deep learning, which is concerned with the study of neural networks comprising many layers. New algorithm was required.\r\n1.2 Deep learning for ecological networks\r\nAn ecological network is typically described as a graph G = (V, E) with vertices V representing species, and edges E describing the interactions between the species. This framework allows edges to be either directed or undirected, which means that the interaction can flow from one species to another (in the case of a food web), or the interaction can be mutual (in the case of a host-parasite network). In some networks,\r\nthe edge can also be weighted, to describe the strength of an interaction. This is often used in food webs, to show the rate of flow of energy between species. Binary networks can be considered a special case of weighted networks, where the edge weights are simply set to either 0 or 1. Additionally, the edges can be labelled to represent different types of interaction - these networks are known as multilayer networks. The vertices of an ecological network can also be labelled, for example in bipartite networks where the vertices are labelled so that they belong to one of two groups. Networks such as host-parasite or seed dispersal networks are generally bipartite, since a single species is rarely both a host and parasite.\r\nFor mathematical convenience, a network can be described by an adjacency matrix. A network with n species would be represented by a real-valued n × n adjacency matrix A, where \\(A_{ij}\\) is the weight of the interaction between the i-th species and the j-th species. This means that the adjacency matrix is symmetric in undirected networks, and asymmetric in directed networks.\r\nTopological analysis\r\nA key aim of ecosystem analysis is to determine how stable an ecosystem is, and how it might react to environmental change. Therefore, a large amount of research has been concerned with determining the stability of ecosystems using theoretical techniques. These ideas were introduced by Elton, who described a community matrix M of size n × n for which the (i, j)-th entry represents the impact that a species h has on another species j around an equilibrium point of some unobserved dynamical system. This allowed stability analysis techniques from dynamical systems literature to be used, where a system is considered stable to small perturbations if the eigenvalues λ of M all have negative real parts. The original study was concerned with random community matrices, but the same ideas have since been refined and applied to realistic community matrices. This area of research has been used to contribute to the ongoing debate about the relationship between biodiversity and ecosystem stability.\r\nSpecies importance metrics\r\nIt is often of interest to ecologists which species are the most influential within their ecosystem. These species are known as keystone species. This has consequences in conservation, since the loss of a keystone species could lead to the collapse of an entire ecosystem. Traditionally, keystone species were identified from their natural history, but it is often difficult to experimentally verify this. This has led to\r\nthe introduction of graph-theoretic species importance metrics which aim to discover keystone species by considering the topology of the network.\r\nNetwork structure prediction\r\nMachine learning algorithms are able to discover patterns in data, and use those patterns to make predictions about previously unseen data samples. This had led to widespread use of ML in many different domains to automate laborious tasks which are expensive in terms of both time and money. Ecological networks are generally constructed in such ways, and therefore it is highly desirable to develop\r\nmachine learning algorithms which automate the process.\r\nMissing link prediction\r\nMissing link prediction - as the name suggests - is the problem of predicting which links are missing from a network. There is a wealth of literature in network analysis concerning this problem and its applications to a range of complex networks. Recently, attention has turned to the problem of link prediction in the context of ecological networks. This has immediately useful practical applications in ecology. The randomness present in an ecosystem makes it unlikely that all actual interactions are\r\nobserved when collecting data to construct ecological networks. Therefore, the use of link prediction algorithms could help ecologists to discover actual unobserved interactions when used in conjunction with traditional ecological network construction methods.\r\n2. Deep learning including fully-connected neural networks\r\n2.1 Linear model with a single or multiple input\r\nThe most impressive advances in artificial intelligence have been in the field of deep learning. Deep learning is an approach to machine learning characterized by deep stacks of computations, which can disentangle the kinds of complex and hierarchical patterns in the most challenging real-world datasets. Their power and scalabile neural networks have become the defining model of deep learning.\r\nNeural networks are composed of neurons, where each neuron individually performs only a simple computation. The fundamental component of a neural network is the individual neuron(see box).\r\n\r\n\r\n\r\nBox : The models with single and multiple inputs\r\n\r\n\r\nSingle Input\r\nThough individual neurons will usually only function as part of a larger network, it’s often useful to start with a single neuron model as a baseline. Single neuron models are linear models.\r\nFor example, training a model with ‘sugars’ (grams of sugars per serving) as input and ‘calories’ (calories per serving) as output in the dataset of cereals, we might find the bias is \\(b=90\\) and the weight is \\(w=2.5\\). We could estimate the calorie content of a cereal with 5 grams of sugar per serving like this:\r\n\r\n\r\n\r\nMultiple Inputs\r\nThe 80 Cereals dataset has many more features than just ‘sugars’. What if we wanted to expand our model to include things like fiber or protein content? That’s easy enough. We can just add more input connections to the neuron, one for each additional feature. To find the output, we would multiply each input to its connection weight and then add them all together.\r\n\r\n\r\n\r\nThe formula for this neuron would be \\(y=w_{0}x_{0}+w_{1}x_{1}+w_{2}x_{2}+b\\). A linear unit with two inputs will fit a plane, and a unit with more inputs than that will fit a hyperplane.\r\n\r\n\r\n\r\n\r\n\r\nHere describe a diagram of a neuron or unit. Does the formula \\(y=wx+b\\) look familiar? It’s the slope-intercept equation, where \\(w\\) is the slope and \\(b\\) is the y-intercept.\r\n\r\nThe Linear Unit: y=wx+b\r\nThe input is \\(x\\). Its connection to the neuron has a weight which is \\(w\\). Whenever a value flows through a connection, you multiply the value by the connection’s weight. For the input \\(x\\), what reaches the neuron is \\(w * x\\). A neural network “learns” by modifying its weights.\r\nThe b is a special kind of weight we call the bias. The bias doesn’t have any input data associated with it; instead, we put a 1 in the diagram so that the value that reaches the neuron is just \\(b\\) (since \\(1 * b = b\\)). The bias enables the neuron to modify the output independently of its inputs.\r\nThe \\(y\\) is the value the neuron ultimately outputs. To get the output, the neuron sums up all the values it receives through its connections. This neuron’s activation is \\(y = w * x + b\\), or as a formula \\(y = wx+b\\).\r\n\r\n\r\n# Create a network with 1 linear unit\r\n#model = keras.Sequential([\r\n#    layers.Dense(units=1, input_shape=[3])\r\n#])\r\n\r\n\r\nThe first argument, units, defining how many outputs we want. In this case just predicting ‘calories’, so units=1. The second argument, input_shape, telling Keras the dimensions of the inputs. Setting input_shape=[3] ensures the model will accept three features as input (‘sugars’, ‘fiber’, and ‘protein’). This model is now ready to be fit to training data!\r\n2.2 Stacking many linear models for deep neural networks\r\nWe can build neural networks capable of learning the complex kinds of relationships that deep neural nets work for. The key idea here is that we can combine and modify these single units to model more complex relationships. We have some nonlinearity with activation functions, let’s see the box2 to understand how we can stack layers to get complex data transformations.\r\n\r\n\r\n\r\nBox : The models with single and multiple inputs\r\n\r\n\r\nLayers\r\nNeural networks typically organize their neurons into layers. We collect together linear units, and then get a dense layer through a common set of inputs. A layer can be, essentially, any kind of data transformation. Many layers, like the convolutional and recurrent layers, transform data through use of neurons and differ primarily in the pattern of connections they form. Others though are used for feature engineering or just simple arithmetic.\r\n\r\nYou could think of each layer in a neural network as performing some kind of relatively simple transformation. Through a deep stack of layers, a neural network can transform its inputs in more and more complex ways. In a well-trained neural network, each layer is a transformation getting us a little bit closer to a solution.\r\nThe Activation Function\r\nDense layers by themselves can never move us out of the world of lines and planes. Without activation functions, neural networks can only learn linear relationships. What we need are activation functions to fit curves. The most common activation function is the rectifier function max(0,x).\r\n\r\nThe rectifier function has a graph that’s a line with the negative part “rectified” to zero. Applying the function to the outputs of a neuron will put a bend in the data, moving us away from simple lines.\r\nWhen we attach the rectifier to a linear unit, we get a rectified linear unit or ReLU. Applying a ReLU activation to a linear unit means the output becomes \\(max(0, w * x + b)\\), which we might draw in a diagram like:\r\n\r\n\r\n\r\n\r\n\r\n\r\nWe build deep neural networks by stacking layers inside a Sequential model. By adding an activation function after the hidden layers, we gave the network the ability to learn more complex (non-linear) relationships in the data.\r\n\r\nNow, notice that the final (output) layer is a linear unit (meaning, no activation function). That makes this network appropriate to a regression task, where we are trying to predict some arbitrary numeric value. Other tasks (like classification) might require an activation function on the output.\r\nThe Sequential model we’ve been using will connect together a list of layers in order from first to last: the first layer gets the input, the last layer produces the output. This creates the model in the figure above:\r\n\r\n\r\n#model = keras.Sequential([\r\n    # the hidden ReLU layers\r\n#    layers.Dense(units=4, activation='relu', input_shape=[2]),\r\n#    layers.Dense(units=3, activation='relu'),\r\n#    # the linear output layer \r\n##])\r\n\r\n\r\nAs for the dataset of of cereals, we’ve chosen a three-layer network with over 1500 neurons. This network should be capable of learning fairly complex relationships in the data.\r\n\r\n\r\n\r\n3. Training neutral network models\r\nLike machine learning tasks, training a network model in fact is to adjust its weights so that it can transform the features (inputs) into the target (output). the dataset of cereals, for instance, we want a network that can take each cereal ‘sugar’, ‘fiber’, and ‘protein’ content and produce a prediction for that cereal ‘calories’. If successfully train a network to do that, its weights must represent some relationships between those features and that target.\r\n\r\n\r\n\r\nBox : The models with single and multiple inputs\r\n\r\n\r\nThe Loss Function\r\nThe loss function measures the disparity between the the target’s true value and the value the model predicts. Different problems call for different loss functions. A common loss function for regression is the mean absolute error (MAE), i.e., abs(y_true - y_pred).\r\n\r\nBesides MAE, other loss functions you might see for regression problems are the mean-squared error (MSE) or the Huber loss (both available in Keras).\r\nThe Activation Function\r\nVirtually all of the optimization algorithms used in deep learning belong to a family called stochastic gradient descent. They are iterative algorithms that train a network in steps like this:\r\nSample some training data and run it through the network to make predictions.\r\nMeasure the loss between the predictions and the true values.\r\nFinally, adjust the weights in a direction that makes the loss smaller.\r\n\r\nEach iteration’s sample of training data is called a minibatch (often “batch”), while a complete round of the training data is called an epoch. The number of epochs you train is how many times the network will see each training example.\r\nThe animation shows the linear model, which is trained with SGD. The pale red dots depict the entire training set, while the solid red dots are the minibatches. Every time SGD sees a new minibatch, it will shift \\(w\\) and \\(b\\) toward their correct values on that batch. Batch after batch, the line eventually converges to its best fit.\r\nLearning Rate and Batch Size\r\nThe learning rate and the size of the minibatches are the two parameters that have the largest effect on how the SGD training proceeds. Fortunately, for most work it won’t be necessary to do an extensive hyperparameter search to get satisfactory results. Adam is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning. Adam is a great general-purpose optimizer.\r\n\r\n\r\n\r\n\r\n\r\nAfter understanding the two things, we should compile in the optimizer and loss function.\r\n\r\n\r\n\r\nNow we’re ready to start the training! We’ve told Keras to feed the optimizer 256 rows of the training data at a time (the batch_size) and to do that 10 times all the way through the dataset (the epochs).\r\n\r\n\r\n\r\n4. Improving the performance of network models\r\n4.1 Increasing capacity and including early stop\r\nKeras will keep a history of the training and validation loss over the epochs that it is training the model. We’ll examine the learning curves for evidence of underfitting and overfitting for correcting it.\r\nLearning Curves\r\nWe train a model by choosing weights or parameters that minimize the loss on a training set. We need to evaluate it on a new set of data, the validation data, to accurately assess a model’s performance.\r\nWhen we train a model we’ve been plotting the loss on the training set epoch by epoch. To this we’ll add a plot the validation data too. These plots we call the learning curves.\r\n\r\nWhen a model learns signal both curves go down, but when it learns noise a gap is created in the curves. The size of the gap tells you how much noise the model has learned. Ideally, we would create models that learn all of the signal and none of the noise. We can get the model to learn more signal at the cost of learning more noise. So long as the trade is in our favor, the validation loss will continue to decrease.\r\nCapacity\r\nA model’s capacity refers to the size and complexity of the patterns it is able to learn. For neural networks, this will largely be determined by how many neurons it has and how they are connected together. If it appears that your network is underfitting the data, you should try increasing its capacity.\r\nYou can increase the capacity of a network either by making it wider (more units to existing layers) or by making it deeper (adding more layers). Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones. Which is better just depends on the dataset.\r\n\r\n\r\n\r\nEarly Stopping\r\nWhen a model is too eagerly learning noise, the validation loss may start to increase during training. To prevent this, we can simply stop the training whenever it seems the validation loss isn’t decreasing anymore. Interrupting the training this way is called early stopping.\r\n\r\nOnce we detect that the validation loss is starting to rise again, we can reset the weights back to where the minimum occured. This ensures that the model won’t continue to learn noise and overfit the data.\r\nIn Keras, we include early stopping in our training through a callback. A callback is just a function you want run every so often while the network trains. The early stopping callback will run after every epoch.\r\n\r\n\r\n\r\n4.2 Dropout and Batch Normalization\r\nThere are some special layers that do not contain any neurons, but that they are added prevent overfitting and stabilize training.\r\nDropout\r\nTo break up these conspiracies, we randomly drop out some fraction of a layer’s input units every step of training, making it much harder for the network to learn those spurious patterns in the training data. Instead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\r\nYou could also think about dropout as creating a kind of ensemble of networks. The predictions will no longer be made by one big network, but instead by a committee of smaller networks. Individuals in the committee tend to make different kinds of mistakes, but be right at the same time, making the committee as a whole better than any individual. (If you’re familiar with random forests as an ensemble of decision trees, it’s the same idea.)\r\n\r\nIn Keras, the dropout rate argument rate defines what percentage of the input units to shut off. Put the Dropout layer just before the layer you want the dropout applied to:\r\n\r\n\r\n\r\nBatch Normalization\r\nAnother special layer is “batch normalization” (or “batchnorm”), which can help correct training that is slow or unstable.\r\nWith neural networks, it’s generally a good idea to put all of your data on a common scale, perhaps with something like scikit-learn’s StandardScaler or MinMaxScaler. Now, if it’s good to normalize the data before it goes into the network, maybe normalizing inside the network would be better! This special kind of layer can do this. A batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then putting the data on a new scale with two trainable rescaling parameters.\r\nIt seems that batch normalization can be used at almost any point in a network. You can put it after a layer…\r\n\r\n\r\n\r\n… or between a layer and its activation function:\r\n\r\n\r\n\r\nAnd if you add it as the first layer of your network it can act as a kind of adaptive preprocessor, standing in for something like Sci-Kit Learn’s StandardScaler.\r\n5. Setup R environment for deeep learning\r\n5.1 R packages for neural networks\r\nThere are some packages that can fit basic neural networks. The nnet package is one package and it can fit feed-forward neural networks with one hidden layer. The neuralnet package fits neural networks with multiple hidden layers and can train them using back-propagation. We will also use the RSNNS package, which is an R wrapper of the Stuttgart Neural Network Simulator (SNNS). The RSNNS package makes many model components from SNNS available, making it possible to train a wide variety of models.\r\nThe deepnet package provides a number of tools for deep learning in R. Specifically, it can train RBMs and use these as part of DBNs to generate initial values to train deep neural networks. The deepnet package also allows for different activation functions, and the use of dropout for regularization.\r\n5.2 Deep learning frameworks for R\r\nThere are a number of R packages available for neural networks, but few options for deep learning. The h2o (https://www.h2o.ai/) is an excellent, general machine learning framework written in Java, and has an API that allows you to use it from R. However, most deep learning practitioners prefer other deep learning libraries, such as TensorFlow, CNTK, and MXNet. There is a good choice of deep learning libraries that are supported in R—MXNet and Keras. Keras is actually a frontend abstraction for other deep learning libraries, and can use TensorFlow in the background. We will use MXNet, Keras, and TensorFlow in this class.\r\nMXNet\r\nMXNet is a deep learning library developed by Amazon. It can run on CPUs and GPUs. Apache MXNet is a flexible and scalable deep learning framework that supports convolutional neural networks (CNNs) and long short-term memory networks (LSTMs). It can be distributed across multiple processors/machines and achieves almost linear scale on multiple GPUs/CPUs. It is easy to install on R and it supports a good range of deep learning functionality for R.\r\nKeras\r\nKeras is a high-level, open source, deep learning framework created by Francois Chollet from Google that emphasizes iterative and fast development; it is generally regarded as one of the best options to use to learn deep learning. Keras has a choice of backend lower-level frameworks: TensorFlow, Theano, or CNTK, but it is most commonly used with TensorFlow. Keras models can be deployed on practically any environment, for example, a web server, iOS, Android, a browser, or the Raspberry Pi.\r\nTo learn more about using Keras in R, go to https://keras.rstudio.com; this link will also has more examples of R and Keras, as well as a handy Keras cheat sheet that gives a thorough reference to all of the functionality of the R Keras package. To install the keras package for R, run the following code:\r\n\r\n\r\n#devtools::install_github(\"rstudio/keras\")\r\n#library(keras)\r\n#install_keras()\r\n\r\n\r\nPlease pay much attention to the link of the different languages, and understand it for operating on them.\r\n\r\nFor ubuntu, you should make sure which python that you can use, and create a virtual environment, such as python3.8-venv, for running keras in Rstudio.\r\n\r\n\r\n#reticulate::py_config()\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "models/2023-10-15-advanced-machine-learning/multi_layer.png",
    "last_modified": "2023-10-15T21:45:34+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-common-machine-learning/",
    "title": "Lesson 1: Common machine learning",
    "description": "Conservation science depends on an accurate understanding of what's happening in a given ecosystem. How many species live there? What is the makeup of the population? How is that changing over time? Species Distribution Modeling seeks to predict the spatial (and sometimes temporal) patterns of species occurrence, i.e. where a species is likely to be found. The last few years have seen a surge of interest in applying powerful machine learning tools to challenging problems in ecology. Our goal in this work is to introduce ecologically useful ML-based algorithms.",
    "author": [],
    "date": "2023-10-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. From statistics to machine learning\r\n2. Machine learning and its main types\r\n3. Training models with R packages\r\n3.1 Data collection and importing\r\n3.2 Exploratory Data Analysis (EDA)\r\n3.3 Data Preprocessing\r\n3.4 Model training and Evaluation\r\n\r\n4. other resoures\r\n\r\n1. From statistics to machine learning\r\nLinear regression analysis estimates the value of one variable relative to the value of another. Linear regression is frequently used in statistical data analysis, i.e., according to least squares, you can calculate its coefficient and intercept. For more details, please check the book. The model performance is examined by \\(R^2\\), and the significance for \\(R^2\\).\r\n.\r\nLinear regression is also achieved via a machine learning algorithm. That is, gradient descent (GD). The operation of GD works by starting with random values for each coefficient. The sum of the squared errors are calculated for each pair of input and output values. A learning rate is used as a scale factor and the coefficients are updated in the direction towards minimizing the sum square errors. The process is repeated until a minimum sum squared error is achieved or no further improvement is possible.\r\n2. Machine learning and its main types\r\nThe two main paradigms of ML are supervised and unsupervised learning. Supervised learning is a subfield of ML concerned with finding a function f such that \\(\\hat{y} = f(x)\\) where x is an input sample vector, y is an output sample vector, and \\(\\hat{y}\\) is a predictor of y. Common supervised learning tasks include classification and regression. Unsupervised learning aims to find a function g which transforms an input\r\nsample x to a representation z in order to reveal underlying information about the input sample. A common unsupervised learning task is clustering.\r\nIn machine learning algorithms, a parameterisable function \\(f_{θ}\\) is often defined. The parameters θ of the function can then be learned through an iterative process of updating the parameters and evaluating the performance of the function. This process is known as optimisation or training; these training algorithms often rely on a\r\nfunction \\(L(y, \\hat{y})\\) which quantifies how incorrect a prediction is compared to the target vector. This is usually known as the cost, error, or loss function, and is chosen depending on the task in hand.\r\nDuring optimisation, parameters are adjusted according to training data. In the case of supervised learning, training data comprises pairs of input and output vectors, each taking the form (x, y). The algorithm will be shown each data sample multiple times. The number of times an algorithm “sees” the entire set of training data is known as an epoch, and is used as a measure of how much an algorithm has been trained. In some circumstances, an algorithm can perform well on the training data but does not perform well on new data. This is known as overfitting, and occurs when the algorithm has learned to predict the target output of each sample in the training data by random noise in the input features, rather than by the important underlying variables.\r\nOverfitting can be detected by splitting the training data into three sets: training, validation, and test. Under this split, the algorithm is trained on the training set, and after each epoch is evaluated on the validation set. When the performance on the validation set does not increase, the algorithm has stopped learning useful properties and has begun to overfit. The algorithm can then be stopped -known as early-stopping - and evaluated on the unseen test set to give a true indication of the algorithm’s performance. The general configuration of the function f is usually governed by hyperparameters, which - unlike parameters - are fixed and are not adjusted during training.\r\nML algorithms are attractive options for solving some problems, because the learned functions \\(f_{θ}\\) are derived directly from the training data without intervention. This makes ML algorithms particularly useful on complex problems for which it is difficult or near-impossible to manually define suitable functions. However, the usefulness of ML is not limited to predictive tasks; after training the learned function can also be interpreted to yield useful information about the data.\r\n3. Training models with R packages\r\nBelow, we’ll examine fundamental machine learning ideas, methods, and a step-by-step procedure of machine learning model developments by utilizing Caret package. Please check this website for details. In this section, we need the libraries, including:\r\nggplot2: for interactive graphs and visualization.\r\nggpubr: for making plot beautiful along with that of ggplot2.\r\nreshape: for melting dataset.\r\ncaret: providing many machine learning algorithms.\r\n\r\n\r\n\r\nWe will walk through each step of implementing Caret package in this part. The general steps to be followed in any Machine learning project are:\r\n3.1 Data collection and importing\r\nNext, we will import our data to a R environment.\r\n\r\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r\n1          5.1         3.5          1.4         0.2  setosa\r\n2          4.9         3.0          1.4         0.2  setosa\r\n3          4.7         3.2          1.3         0.2  setosa\r\n4          4.6         3.1          1.5         0.2  setosa\r\n5          5.0         3.6          1.4         0.2  setosa\r\n6          5.4         3.9          1.7         0.4  setosa\r\n\r\n3.2 Exploratory Data Analysis (EDA)\r\nUnderstanding and assessing the data you have for your project is one of the important steps in the modeling preparation process. This is accomplished through the use of data exploration, visualization, and statistical data summarization with a measure of central tendencies. You will gain an understanding of your data during this phase, and you will take a broad view of it to get ready for the modeling step.\r\n\r\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \r\n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \r\n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \r\n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \r\n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \r\n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \r\n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \r\n       Species  \r\n setosa    :50  \r\n versicolor:50  \r\n virginica :50  \r\n                \r\n                \r\n                \r\n\r\nVisualizing the outliers by using boxplot. As we use ggplot2 we will take numerical variables by subsetting the entire of it. Using of reshape package we melt the data and plot it to check for the presence of any outliers.\r\n\r\n\r\n\r\nLet’s now use a histogram plot to visualize the distribution of our data’s continuous variables.\r\n\r\n\r\n\r\nNext, we will move to the Data Preparation phase of our machine learning process. Before that, lets split our dataset into train, test and validation partition.\r\n\r\n\r\n\r\n3.3 Data Preprocessing\r\nThe quality of our good predictions from the model depends on the quality of the data itself, data preprocesing is one of the most important steps in machine learning. We can see from the box plot that there are outliers in our data, and the histogram also shows how skewed the data is on the right and left sides. We shall thus eliminate those outliers from our data.\r\n\r\n\r\n\r\nAfter obtaining the quantile value, we will additionally compute the interquartile range in order to determine the upper and lower bound cutoff values. Then, we eliminate the outliers.\r\n\r\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\r\n1            5.1         3.5          1.4         0.2     setosa\r\n2            4.9         3.0          1.4         0.2     setosa\r\n3            4.7         3.2          1.3         0.2     setosa\r\n4            4.6         3.1          1.5         0.2     setosa\r\n5            5.0         3.6          1.4         0.2     setosa\r\n6            5.4         3.9          1.7         0.4     setosa\r\n7            4.6         3.4          1.4         0.3     setosa\r\n8            5.0         3.4          1.5         0.2     setosa\r\n9            4.4         2.9          1.4         0.2     setosa\r\n10           4.9         3.1          1.5         0.1     setosa\r\n11           5.4         3.7          1.5         0.2     setosa\r\n12           4.8         3.4          1.6         0.2     setosa\r\n13           4.8         3.0          1.4         0.1     setosa\r\n14           4.3         3.0          1.1         0.1     setosa\r\n15           5.8         4.0          1.2         0.2     setosa\r\n18           5.1         3.5          1.4         0.3     setosa\r\n19           5.7         3.8          1.7         0.3     setosa\r\n20           5.1         3.8          1.5         0.3     setosa\r\n21           5.4         3.4          1.7         0.2     setosa\r\n23           4.6         3.6          1.0         0.2     setosa\r\n24           5.1         3.3          1.7         0.5     setosa\r\n25           4.8         3.4          1.9         0.2     setosa\r\n26           5.0         3.0          1.6         0.2     setosa\r\n27           5.0         3.4          1.6         0.4     setosa\r\n29           5.2         3.4          1.4         0.2     setosa\r\n30           4.7         3.2          1.6         0.2     setosa\r\n31           4.8         3.1          1.6         0.2     setosa\r\n35           4.9         3.1          1.5         0.2     setosa\r\n37           5.5         3.5          1.3         0.2     setosa\r\n38           4.9         3.6          1.4         0.1     setosa\r\n39           4.4         3.0          1.3         0.2     setosa\r\n40           5.1         3.4          1.5         0.2     setosa\r\n43           4.4         3.2          1.3         0.2     setosa\r\n44           5.0         3.5          1.6         0.6     setosa\r\n45           5.1         3.8          1.9         0.4     setosa\r\n46           4.8         3.0          1.4         0.3     setosa\r\n48           4.6         3.2          1.4         0.2     setosa\r\n50           5.0         3.3          1.4         0.2     setosa\r\n51           7.0         3.2          4.7         1.4 versicolor\r\n52           6.4         3.2          4.5         1.5 versicolor\r\n53           6.9         3.1          4.9         1.5 versicolor\r\n54           5.5         2.3          4.0         1.3 versicolor\r\n56           5.7         2.8          4.5         1.3 versicolor\r\n57           6.3         3.3          4.7         1.6 versicolor\r\n59           6.6         2.9          4.6         1.3 versicolor\r\n62           5.9         3.0          4.2         1.5 versicolor\r\n63           6.0         2.2          4.0         1.0 versicolor\r\n64           6.1         2.9          4.7         1.4 versicolor\r\n66           6.7         3.1          4.4         1.4 versicolor\r\n67           5.6         3.0          4.5         1.5 versicolor\r\n68           5.8         2.7          4.1         1.0 versicolor\r\n70           5.6         2.5          3.9         1.1 versicolor\r\n71           5.9         3.2          4.8         1.8 versicolor\r\n73           6.3         2.5          4.9         1.5 versicolor\r\n74           6.1         2.8          4.7         1.2 versicolor\r\n75           6.4         2.9          4.3         1.3 versicolor\r\n76           6.6         3.0          4.4         1.4 versicolor\r\n77           6.8         2.8          4.8         1.4 versicolor\r\n78           6.7         3.0          5.0         1.7 versicolor\r\n80           5.7         2.6          3.5         1.0 versicolor\r\n81           5.5         2.4          3.8         1.1 versicolor\r\n82           5.5         2.4          3.7         1.0 versicolor\r\n84           6.0         2.7          5.1         1.6 versicolor\r\n85           5.4         3.0          4.5         1.5 versicolor\r\n86           6.0         3.4          4.5         1.6 versicolor\r\n87           6.7         3.1          4.7         1.5 versicolor\r\n88           6.3         2.3          4.4         1.3 versicolor\r\n89           5.6         3.0          4.1         1.3 versicolor\r\n90           5.5         2.5          4.0         1.3 versicolor\r\n91           5.5         2.6          4.4         1.2 versicolor\r\n92           6.1         3.0          4.6         1.4 versicolor\r\n93           5.8         2.6          4.0         1.2 versicolor\r\n94           5.0         2.3          3.3         1.0 versicolor\r\n95           5.6         2.7          4.2         1.3 versicolor\r\n96           5.7         3.0          4.2         1.2 versicolor\r\n97           5.7         2.9          4.2         1.3 versicolor\r\n100          5.7         2.8          4.1         1.3 versicolor\r\n102          5.8         2.7          5.1         1.9  virginica\r\n103          7.1         3.0          5.9         2.1  virginica\r\n104          6.3         2.9          5.6         1.8  virginica\r\n105          6.5         3.0          5.8         2.2  virginica\r\n107          4.9         2.5          4.5         1.7  virginica\r\n108          7.3         2.9          6.3         1.8  virginica\r\n109          6.7         2.5          5.8         1.8  virginica\r\n110          7.2         3.6          6.1         2.5  virginica\r\n111          6.5         3.2          5.1         2.0  virginica\r\n114          5.7         2.5          5.0         2.0  virginica\r\n115          5.8         2.8          5.1         2.4  virginica\r\n117          6.5         3.0          5.5         1.8  virginica\r\n118          7.7         3.8          6.7         2.2  virginica\r\n119          7.7         2.6          6.9         2.3  virginica\r\n120          6.0         2.2          5.0         1.5  virginica\r\n121          6.9         3.2          5.7         2.3  virginica\r\n123          7.7         2.8          6.7         2.0  virginica\r\n124          6.3         2.7          4.9         1.8  virginica\r\n126          7.2         3.2          6.0         1.8  virginica\r\n127          6.2         2.8          4.8         1.8  virginica\r\n128          6.1         3.0          4.9         1.8  virginica\r\n129          6.4         2.8          5.6         2.1  virginica\r\n130          7.2         3.0          5.8         1.6  virginica\r\n131          7.4         2.8          6.1         1.9  virginica\r\n132          7.9         3.8          6.4         2.0  virginica\r\n134          6.3         2.8          5.1         1.5  virginica\r\n135          6.1         2.6          5.6         1.4  virginica\r\n136          7.7         3.0          6.1         2.3  virginica\r\n137          6.3         3.4          5.6         2.4  virginica\r\n138          6.4         3.1          5.5         1.8  virginica\r\n139          6.0         3.0          4.8         1.8  virginica\r\n140          6.9         3.1          5.4         2.1  virginica\r\n142          6.9         3.1          5.1         2.3  virginica\r\n143          5.8         2.7          5.1         1.9  virginica\r\n145          6.7         3.3          5.7         2.5  virginica\r\n146          6.7         3.0          5.2         2.3  virginica\r\n147          6.3         2.5          5.0         1.9  virginica\r\n148          6.5         3.0          5.2         2.0  virginica\r\n149          6.2         3.4          5.4         2.3  virginica\r\n150          5.9         3.0          5.1         1.8  virginica\r\n\r\nBy using a boxplot, we can additionally see the outliers that were eliminated from the data.\r\n\r\n\r\n\r\n3.4 Model training and Evaluation\r\nIt’s time to use the clean data to create a model. We don’t have a specific algorithm in mind, Let’s compare LDA and SVM for practical purposes and choose the best one. For accuracy and prediction across all samples, we will employ 10-fold cross validation.\r\n\r\n\r\n\r\nLet’s start training model with Linear Discriminant Analysis.\r\n\r\nLinear Discriminant Analysis \r\n\r\n120 samples\r\n  4 predictor\r\n  3 classes: 'setosa', 'versicolor', 'virginica' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 108, 108, 108, 108, 108, 108, ... \r\nResampling results:\r\n\r\n  Accuracy  Kappa \r\n  0.975     0.9625\r\n\r\nWe can also use SVM model for the training.\r\n\r\nSupport Vector Machines with Radial Basis Function Kernel \r\n\r\n120 samples\r\n  4 predictor\r\n  3 classes: 'setosa', 'versicolor', 'virginica' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 108, 108, 108, 108, 108, 108, ... \r\nResampling results across tuning parameters:\r\n\r\n  C     Accuracy   Kappa\r\n  0.25  0.9333333  0.900\r\n  0.50  0.9500000  0.925\r\n  1.00  0.9333333  0.900\r\n\r\nTuning parameter 'sigma' was held constant at a value of 0.7381148\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final values used for the model were sigma = 0.7381148 and C\r\n = 0.5.\r\n\r\nThe results show that both algorithms functioned admirably with only minor variations. Although the model can be tuned to improve its accuracy accurate, for the purposes of this lesson, let’s stick with LDA and generate predictions using test data.\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         10          0         0\r\n  versicolor      0         10         0\r\n  virginica       0          0        10\r\n\r\nOverall Statistics\r\n                                     \r\n               Accuracy : 1          \r\n                 95% CI : (0.8843, 1)\r\n    No Information Rate : 0.3333     \r\n    P-Value [Acc > NIR] : 4.857e-15  \r\n                                     \r\n                  Kappa : 1          \r\n                                     \r\n Mcnemar's Test P-Value : NA         \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            1.0000           1.0000\r\nSpecificity                 1.0000            1.0000           1.0000\r\nPos Pred Value              1.0000            1.0000           1.0000\r\nNeg Pred Value              1.0000            1.0000           1.0000\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.3333           0.3333\r\nDetection Prevalence        0.3333            0.3333           0.3333\r\nBalanced Accuracy           1.0000            1.0000           1.0000\r\n\r\nAccording to the summary of our model above, We see that the prediction performance is poor; this may be because we neglected to consider the LDA algorithm’s premise that the predictor variables should have the same variance, which is accomplished by scaling those features. We won’t deviate from the topic of this lesson because we are interested in developing machine learning utilizing the Caret module in R.\r\n4. other resoures\r\nHere is a concise guide to machine learning techniques for ecological data. This practical guide to machine learning includes explaining and exploring different machine learning techniques, from CARTs to GBMs, using R.\r\n\r\n\r\n\r\n",
    "preview": "models/2023-10-15-common-machine-learning/distill-preview.png",
    "last_modified": "2023-10-15T21:29:20+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-deep-learning-as-data-driven-methods/",
    "title": "Lesson 3: Deep Learning as Data-driven Methods",
    "description": "The immediate aim of this section is to develop a data-driven machine learning algorithm to predict which interactions are missing from ecological networks, and to explore ways in which ecological insight can be extracted from the algorithm. In particular, we introduce key concepts and terminology of data-driven models.",
    "author": [],
    "date": "2023-10-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. What are neural networks and how do they learn?\r\n2. Appplications of deep learning to ecology and evolution\r\n2.1 Automated species identification\r\n2.2 Environmental monitoring and modeling\r\n2.3 Behavioral studies\r\n2.4 Genomics, population genetics, and phylogenetics\r\n\r\n\r\nEcology and evolutionary biology investigate complex patterns and processes. A mathematical toolkit has been necessary to describe and explain fundamental components of organic evolution and ecological interactions. This wealth of data is driving the development of analytic tools that can provide new understanding, greater efficiency, and ease of use. Likelihood-based mechanistic approaches designed to consider many variables can be so computationally expensive that they can no longer be applied to data routinely generated in modern studies. A promising alternative is likelihood-free inference, one example of which is machine learning. The goal of machine learning is to find a model that performs well at making predictions from the data. This contrasts with likelihood-based methods, which assume the model generating the data is known. More recently machine learning has seen a dramatic surge in popularity\r\nwith a slew of new algorithms and applications.\r\nOne of the approaches rapidly gaining popularity is deep learning. Deep learning relies on multilayered, connected processing units (artificial neural networks or ANNs). The successes of deep learning were possible because of a major advantage of deep learning over classical machine learning approaches. Classical machine learning requires that important data features are identified using expert domain knowledge. Neural networks can automatically discover the most important data features and patterns relevant for the task. Researchers are now beginning to apply deep learning to problems across ecology and evolutionary biology, from community science projects and environmental monitoring through sequencing equipment output processing, to population genetics\r\nand phylogenetic inference.\r\n1. What are neural networks and how do they learn?\r\nHere describe what artificial neural networks are and how they are used as inference tools (Box 1).\r\n\r\n\r\n\r\nBox 1: Common neural network architectures\r\n\r\n\r\nArtificial Neural Networks(ANNs) is a group of multiple perceptrons/ neurons at each layer. Neurons can be connected to other neurons in different layers but not within the same layer. In the simplest form, a neural network has one input layer, at least one intermediate or hidden layer, and an output layer. The trainable network parameters consist of biases and weights. Each node has a bias value (b), which determine how easy it is for it to “fire”. Each connection has a weight value (W) which represents connection strength. Each node also has an activation function (f), for example sigmoid\r\nfunction. Given some input (x), the so-called feedforward output (y) of a node is determined by a simple equation: \\(y = f(W × x + b)\\).\r\nANN is a Feed-Forward Neural network because inputs are processed only in the forward direction. Recurrent neural networks is to add loops to information flow. Information flows from the input to the output of the network but it can flow back from the output to the input of the hidden layer through recurrent weights.\r\n\r\n\r\n\r\nHowever, simple RNNs such as the one shown in the figure are difficult to train because weights in these networks can quickly diverge during training. More advanced RNN, such as Long Short-Term Memory networks (LSTMs) or Gated Recurrent Units (GRUs), address this problem and are commonly used with time series data. In evolutionary biology, deep learning solutions including GRU have been used to predict recombination landscapes. In the field of ecology. reserchers are trying to use deep learning techonologies for the analysis of remote sensing data. The convolutional neural networks (CNNs) can excel at capturing complex, hierarchical patterns and are the architecture used in most identification and classification problems.\r\n\r\n\r\n\r\n\r\nIn mathematical sense, neural networks are simply a function mapping input onto a desired output. This general design is simple, but it makes neural networks\r\nextraordinarily powerful: a network with information flowing from input to output layer with at least one intermediate layer (i.e. feedforward network) can approximate any continuous function, regardless of its complexity. These approximations can describe pixels of an image, for example, and networks with multiple intermediate layers (deep neural networks) can also learn relationships between them as high-level concepts such as lines, geometric shapes, and even whole scenes.\r\nANNs learn continuous distributions but their output can represent probabilities of distinct data classes, as well as continuous values. Such networks can thus be used to construct classifiers, which are models distinguishing among discrete categories, as well as regression models, which infer continuous values. But feedforward operations alone do not allow the network to learn or generalize to new data, which is the essence of most ANN applications.\r\nIn order for an ANN to be a predictive tool, one needs to assess how good predictions are and be able to adjust ANN parameters to improve performance. A measure of how far off the output of the network is is called a loss function. One example of a loss\r\nfunction is the sum of squares error (SSE), which is simply the sum of differences between each predicted value (y) and the true value (\\(\\overline{y}\\)) squared for absolute value:\r\n\\[SEE= \\sum_{i = 1}^{n}(y_i - \\overline{y}_i)^2\\]\r\nThe network also needs a mechanism for finding the set of parameters that minimize the loss function. Once the loss (error) is measured at the output, it has to be traced back across the network to measure how parameters contributed to it. This process is called backpropagation and it uses chain rule calculus to find the derivative (slope) of the loss function with respect to the network’s trainable parameters. The process of increasing or decreasing parameters such that they minimize the derivative of the loss function is called gradient descent. This process is iterative, occurring every time a batch of training data is processed, and collectively referred to as the training loop. When devised correctly, it results in improvement of inference accuracy with each pass of the loop.\r\nThe fact that ANNs are universal approximators for continuous functions that can be trained makes them powerful predictive tools. This learning scheme is most easily illustrated with an example of supervised learning, where the network is trained on a data set, e.g. images of expert-identified species or methylated vs. unmethylated DNA sequences. Supervised training usually involves splitting data into three subsets:\r\ntraining, validation, and testing. The validation set is not directly used in training but prediction on it is performed at the end of each training cycle to assess how well the network generalizes outside of the training set. Test set is held back for the final estimate of accuracy.\r\n2. Appplications of deep learning to ecology and evolution\r\nIn the sections that follow, we review how deep learning has been applied in ecology and evolution, including species identification and monitoring, ecological and behavioral studies, and population genetics and phylogenetics. We use these examples to showcase the variety of deep learning techniques extending its usage beyond the general picture described above.\r\n2.1 Automated species identification\r\nDeep learning enabled breakthroughs in automated image classification, largely possible thanks to CNNs. Image recognition has obvious applications in biology and was\r\nadopted early for problems of species identification and wildlife monitoring. It is not surprising then that identification or classification of individuals or species from image, video, and sound data is the most common use of deep learning in the field. These efforts already span many taxa, from bacteria, through protozoans, plants to insects and vertebrates, both extant and fossil and at scales ranging from local to global. Intensifying efforts to digitize natural history collections provide troves of\r\nimage data that can be used for this purpose.\r\nCamera trap systems and deep learning classifiers are now commonly used for vertebrate wildlife monitoring and systems automating environmental monitoring of aquatic macroinvertebrates are also being developed. Many publications present systems or deep learning models for detecting and identifying pests or crop diseases in agroecosystems or stored agricultural\r\ncommodities. Despite economic importance and demonstrated potential for crop pest and disease monitoring, at present few non-proprietary systems or open source software\r\napplications exist. A notable exception is a mobile application system for identifying diseases of cassava plants, one of the most important tropical crops.\r\nDeep learning has also been applied to identification from audio recordings, including bird and bat sounds, and even wing beats of mosquitoes. Unsurprisingly, the technology has been applied most often to bird calls, where it has been used not only to identify species, but also monitor their abundance. The recently developed BirdNET is a deep neural network capable of identifying North American and European birds from vocalizations in complex soundscapes, available on a variety of platforms, including user-friendly smartphone apps. Most of these studies use audio converted to spectrograms, image representations of sound, to train CNNs as in visual recognition problems.\r\nGiven its utility for automated identification, deep learning is increasingly used in community science initiatives. Examples include a growing number of mobile phone applications such as plant-focused identification app Pl@ntNet, bird identification tool Merlin or the citizen naturalist portal iNaturalist, as well as a number of more local or taxon-specific guides. Many of these applications crowd-source training data collection and identification verification by users. They improve by periodically re-training their deep learning classifiers as more reliable data is collected.\r\nMany of these studies employ data handling approaches that increase performance of deep learning classifiers. Several use data augmentation, a technique that relies on altering training data with distortion. These modifications, applied to each data input in each training epoch, effectively increase training set size. Data augmentation is an important strategy for reducing overfitting and almost always results in increased classifier accuracy. By ensuring that the neural network never sees the same input twice, augmentation only partly addresses the fact that acquiring large, human-labeled datasets is a bottleneck for many applications. An alternative approach is to train an initial classifier in a supervised way, using a labeled training set, and then use this reasonably well-performing classifier for adding more images in an unsupervised manner, without human intervention.\r\nAnother technique ubiquitous in identification and classification tasks is transfer learning. Transfer learning is most commonly accomplished by first training on a different, usually larger and more general dataset than the one assembled for the problem on hand. The resulting network parameters can then be used as the starting point for fine-tuning on the focal dataset. In species recognition from images it is common to use networks pre-trained on large, public datasets of everyday objects such as ImageNet or COCO as illustrated by several of the studies cited above. Using pre-trained networks makes the network learn faster and often results in higher accuracy.\r\nIn addition to properly assigning a label to an image, termed image classification, a common computer vision problem is to localize objects. Object recognition is a term often used for the combination of the two: drawing a bounding box around an object and predicting its class. Because there may be many objects in an image, this is a more challenging problem. The many proposed solutions involve either extracting candidate regions from images prior to prediction or predicting classes directly on grids of image pixels. Examples are common in agriculture, where object detection has been used to identify and count pests.\r\nThe deep learning framework allows training several neural networks of the same or varying architectures on one dataset and averaging their predictions. Known as model ensembling, this technique reduces variance in predictions and can improve accuracy. Examples in species identification include Finnish fungi recognition and UK ladybird beetles.\r\nFinally, deep learning is not limited to considering image pixels alone but can also take advantage of contextual information such as locality or phenology. For example, output can be improved by filtering out\r\nnonsensical predictions given prior occurrence data. This approach, however, does not jointly consider the available data in a common framework. Neural networks can be trained on multiple data inputs simultaneously and consider them jointly in the final layers. One study used this approach for beetle identification from images and found improvement in accuracy with information about location, date, weather, habitat, and\r\nuser expertise.\r\n2.2 Environmental monitoring and modeling\r\nThe above mentioned approaches to automated identification of species or individuals are also being scaled to ecosystem scale and applied to diversity assessment, conservation, and resource management. Examples using techniques detailed\r\nin the previous section include detecting and estimating abundance of zooplankton\r\nand detecting and counting sea turtles and whales using drone and satellite imagery. Other uses combine digital imagery with LiDAR and other remote sensing or geospatial data for mapping of vegetation, forest carbon stock, and the footprint of fishing across the world’s oceans. Similar applications include integrated systems for real-time wildlife monitoring using data from camera traps and microphone and raise the prospect of surveillance of social media posts for illegal animal trade.\r\nIn addition to classification and mapping of static information, RNNs and similar approaches have been used with temporal ecological data. Examples include predicting\r\neutrophication, phytoplankton blooms, and benthic invertebrate community dynamics. As mentioned previously, combining inputs from different sources is natural for deep learning and Rammer and Seidl take advantage of this to predict and map future bark beetle outbreaks based on temporal information on climate, vegetation, and past outbreaks. Capinha et al. proposed a generalized approach to classification and prediction from ecological time series data leveraging automated choice of the best network architecture for the task at hand.\r\nFinally, neural networks are being used to develop more realistic models and simulations of real world patterns and phenomena. Benkendorf and Hawkins found that deep neural networks can be used to generate accurate species distribution models but\r\nalso noted that other machine learning approaches perform as well or better with limited training data. Strydom et al. designed a system to predict species interactions from co-occurrence data. A study using reinforcement learning investigated how learning to hunt or avoid predators by individual agents influenced predator-prey dynamics.\r\n2.3 Behavioral studies\r\nThe study of animal behavior, both in the field and controlled laboratory settings, is another research area of ecology and evolution that is poised to greatly benefit from adoption of deep learning. Recent technological advancements in sensing, monitoring, and automation allow behavioral ecologists to collect and analyze large amounts of data Long-standing challenges in identifying, quantifying, and analyzing animal behavior still limit the ability to fully automate processing of these data, however. Deep learning has the potential to address many of these challenges and it is increasingly being adopted in studies involving identification of individual animals, body posture and movement tracking, and classification of behaviors.\r\nIn the area of animal body posture, deep learning can provide non-invasive estimation of the position of animals’ body parts from video recordings. Several open-source toolkits have been developed for this purpose, ranging from species-specific solutions, to generic frameworks applicable to any species, some of which offer 3-dimensional and/or multiple animals tracking. In addition to pose estimation,\r\ndeep learning is also being adopted to enhance the performance of established computer vision methods used to track spatial position of animal detection or the identification of markers, as well as to automatically perform behavioral analysis of spatial trajectories.\r\nDeep learning can also allow for the identification, classification, and subsequent re-identification of individual animals from camera feeds or traps, both in the wild and in captivity. Usually based on the use of CNNs for image recognition, deep\r\nlearning can also be combined with other technologies to develop automated\r\ndata-processing pipelines to collect and label samples bird species. A popular application in this area is face recognition enabling mark-recapture studies for monitoring populations of individuals, their behavior, and social interactions. Examples in the wild include identification of elephants, chimpanzees, right whales and brown bears. Studies performed in captivity have been carried out\r\non pandas and pigs.\r\nFinally, deep learning is being applied to automatically detect and classify the behavior of animals from raw data, a crucial step towards overcoming time-consuming and error-prone manual labeling tasks. Largely based on CNNs, a number of different solutions have been developed to recognize and label behaviors from images as well as video and sound recordings. These behavior detection systems can discriminate between behaviors, with the possibility of concurrent behaviors and thus multi-labeling, or be specifically designed to detect binary events (e.g. distinguish whale vocalizations from noise, or rare social changes in otherwise stable insect colonies). In addition to behavior recognition, deep learning solutions are also being devised to predict behavioral measurements that would otherwise require specialized recording devices. For example, Browning et al. used artificial neural networks to predict the diving behavior of seabirds from GPS data alone without specialized time-depth records,\r\nwhereas Liu et al. used vertical movement sensors alone to predict locomotor energy expenditure of sharks.\r\n2.4 Genomics, population genetics, and phylogenetics\r\nA rapidly growing number of studies apply deep learning to study genomes. Deep learning is used in DNA sequencing for translating the raw signal of long-read Oxford Nanopore sequencers into nucleotide calls, outperforming other basecallers. Another example of successful application is variant calling, or identification of small nucleotide polymorphisms and indels in diploid or polyploid genomes. DeepVariant is a tool that converts text file representations of multiple sequences aligned to a reference (read pileups) to images and uses a CNN to predict alternative alleles. Another tool predicts gene copy number variations from high-throughput sequencing reads. Deep learning has been particularly successful in functional and regulatory genomics and has been used for predicting sequence specificity of nucleic acidbinding proteins, methylation status, identification of transcription start sites, predicting expression patterns from genotypes, classification of transposable elements, and more. These applications are not strictly within the purview of ecology and evolution and have been comprehensively reviewed elsewhere.\r\nDeep learning is a part of a growing trend to apply machine learning to the study of evolution of populations and species. One of the early studies applying neural networks to population genetic data showed them capable of estimating population-scale mutation rates, population sizes and their changes through time, recombination rates,\r\nand detecting introgressed loci and positive selection on simulated data. That study\r\ndemonstrated that CNNs are capable of estimating population genetic parameters in scenarios for which likelihood-based methods have yet to be developed, such as accurately inferring recombination rates from read coverage data in autotetraploid genomes. The impressive performance of deep learning for population genetics encouraged recent development of user-friendly tools for inference from empirical data, including selective sweep classification, quantifying selection strength, jointly inferring selection and population size change, and inferring recombination landscapes. Other studies relied on custom approaches to identifying deleterious variants in sorghum and positive selection in SARS-CoV-2. An emerging approach involves combining deep learning with approximate Bayesian computation (ABC). It has been applied to inferring population size change through time, identifying hybridization from pairwise nucleotide divergences, and choosing best-fitting demographic scenarios based on site frequency spectra or SNP data. Most of the above approaches use CNNs, which in their standard formulation are sensitive to permutations. This means that the ordering of chromosomes in the input, for example, is significant for training and prediction. Flagel et al. dealt with this by sorting chromosomes by similarity but network architectures insensitive to input ordering are\r\nalso being developed.\r\nDeep learning has also been used for inference and visualization of population structure. Here neural networks are used for dimensionality reduction, similar to\r\nprincipal component analysis, rather than for solving a classification or regression problem. To achieve this, the authors used variational autoencoders (VAEs), a pair of neural networks that learn efficient representations of data in an unsupervised manner. In this method the encoder network compresses input data into latent variables, while the decoder network attempts reconstructing the original data from those variables. The loss function in this case is a combined measure of how good the reconstruction is and desirable properties of latent variables. The goal was to visualize population structure in a two-dimensional space and so the data were compressed into two variables representing coordinates.\r\nAs the importance of the spatial component is becoming increasingly highlighted in population genetics, deep learning is also beginning to be used for predicting sample origins based on genetic variation and local-ancestry inference, which aims to identify populations from which a genetic locus descended. This application involves using generative adversarial networks (GANs) to create artificial human genomic sequences of known ancestry.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-10-15T22:18:25+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-remote-sensing-data-and-models/",
    "title": "Lesson 4: Remote sensing data and models",
    "description": "Remote sensing is the science of identifying, observing, collecting, and measuring objects without coming into direct contact with them. This can be accomplished through many devices that carry sensors and capture the characteristics of Earth remotely. Sensors on board satellites also record the electromagnetic energy that is reflected or emitted from objects on Earth. They are especially useful for natural resoures and a variety of socio-economic research and applications.",
    "author": [],
    "date": "2023-10-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Remote sensing data\r\n2. Data operations and tools\r\n2.1 Download data of aoi\r\n2.2 Merging, cropping and masking\r\n2.3 Extracting values and computing statistics\r\n2.4 Storing and exporting results\r\n\r\n3. A practical example\r\n\r\n1. Remote sensing data\r\nForest Cover Data\r\nThis section is adopted from the module. we will primarily work with the Vegetation Continuous Fields (VCF) data provided by the Land Processes Distributed Active Archive Center (LP DAAC), a component of NASA’s Earth Observing System Data and Information System (EOSDIS). The MOD44B Version 6 VCF is a yearly representation of surface vegetation from 2000 to 2020 at 250 m resolution. Each pixel stores a percentage of three ground cover components: percent tree cover, percent non-tree cover, and percent bare.\r\nThe ground cover percentages are estimates from a machine learning model based on the combination of the Moderate Resolution Imaging Spectroradiometer (MODIS) data and other high resolution data from NASA and Google Earth. The machine learning model incorporates the visible bandwidth as well as other bandwidth such as brightness temperature (from MODIS bands 20, 31, 32).\r\nThe VCF data utilize thermal signatures and other correlates to distinguish forest and non-forest plantation, which is an improvement compared to the Normalized Differenced Vegetation Index (NDVI). For this use case, VCF also improves on the Global Forest Cover (GFC) data set, another source used to study deforestation, which only provides binary data points. GFC records baseline forest cover in the year 2000 and includes a binary indicator for the year of deforestation for each 30m × 30m pixel. If over 90% of the forest cover was lost in a pixel by a given year, then the pixel is marked as deforested, while a pixel is marked as reforested if the forest cover went from 0 in 2000 to a positive value. The VCF records continuous changes in percent of ground cover components, which provides more details than the GFC data.\r\nNighttime lights\r\nThere is a strong correlation between nighttime lights and Gross State Product (GSP) or Gross Domestic Product (GDP) measures, at the national, state and regional levels or even at a more granular resolution. Thus, nighttime light observations can be used as a proxy for economic activity, especially over periods or regions where these data are not available or where the statistical systems are of low quality or when no recent population or economic censuses are available. Similarly, changes in nighttime light intensity can be used by economists as an additional measure of income growth when no other measures of income growth are available.\r\nProville et al. (2017) examined trends observed by DMSP-OLS in the period 1992-2013 and their correlation with a series of socio-economic indicators. They found the strongest correlations between nighttime lights, electricity consumption, CO2 emissions, and GDP, followed by population, CH4 emissions, N2O emissions, poverty and F-gas emissions.\r\n2. Data operations and tools\r\n2.1 Download data of aoi\r\nIn order to perform data manipulation, we need to attach packages. We are going to use the package luna to download data from MODIS and the packages terra, tidyverse, raster, and sf for data manipulation.\r\n\r\n\r\n\r\nWe follow thistutorial to get MODIS data with luna. For details of the terra package, please refer to the package manuscript and this tutorial. If you are not familiar with the tidyverse workflow, please refer to the R for Data Science.\r\nOnce the required packages have been attached, we can access VCF in R. We prefer using R for its ability to download large numbers of files and enable regular, automated updates.\r\nWe can first use luna to check the list of data products available from MODIS. Since luna can also access data from the LANDSAT and SENTINEL platforms, we add “MOD|MYD|^MCD” to narrow our scope to MODIS data. The printed results below list six products from MODIS.\r\n\r\n\r\n\r\nThe product name for VCF is MOD44B. We can use the function productInfo to launch the information page of VCF.\r\n\r\n\r\n\r\nWe can query MODIS and only download a subset of the data. We need to specify the start and end dates and our area of interest (AOI). The date format is “yyyy-mm-dd”. Suppose here we want to subset data from 2010 to 2012.\r\n\r\n\r\n\r\nIn order to subset your area of interest, you need to provide a “map” to getModis(). This can be obtained from online databases such as the global administrative area database (GADM). You can download map data directly from GADM or you can use R to obtain GADM map data. We will use R below, which requires first installing the package geodata.\r\n\r\n\r\n\r\nGeographic levels in GADM are defined as:\r\nlevel 0: National\r\nlevel 1: State/province/equivalent\r\nlevel 2: County/district/equivalent\r\nlevel 3/4: Smaller administrative levels\r\nFor our example, we are interested in India at the district level. We can download the map of India and its level 2 administrative areas with the following code:\r\n\r\n\r\n\r\nThe boundary data is downloaded to the path that you specified in the path argument. The downloaded data through gadm() will be in the PackedSpatVector class. If you want to convert it to another class (for example, the sf class, which is easier to work with in R), you can first read it using readRDS(), then convert to a SpatVector via vect() from the terra package, and finally convert it to a sf object.\r\n\r\n\r\n\r\nThe map we downloaded is at the district level (level 2). Assume our AOI is the state of Odisha. Each row of the data represents a county in Odisha, and the geospatial information for each county is stored in the last column: geometry. We can filter to obtain the boundaries for our AOI, which will return aoi in vector format, stored as a data frame in R.\r\n\r\n\r\n\r\n\r\n\r\n\r\nNow that we have our AOI as well as time frame, we can filter the MODIS VCF data on these values and see what is available.\r\n\r\n\r\n\r\nThe products we are going to download are tiled products. For details of tiled products, the tilling system, and the naming convention, please refer to the MODIS overview page. In essence, we will be downloading grids of maps that cover our AOI.\r\nTo actually download these files from the NASA server, you will need a username and password. Please register on NASA Earth Data if you haven’t done so.\r\nThe following code will download the files. Replace the path value with the location on your computer where you would like to store these files. Replace the username and password values with your NASA Earth Data credentials from above.\r\n\r\n\r\n\r\nThe data format from MODIS is HDF and may include sub-datasets. We can use terra to read these files and create raster files. For example,\r\n\r\n\r\n\r\nWe can find basic information such as the coordinate reference system, number of cells, and resolution from the above output. There are 7 layers in each of the VCF tiled files. We are interested in the percent tree coverage layer.\r\n\r\n\r\n\r\nA quick plot of the data can be done with the plotRBG() function.\r\n\r\n\r\n\r\n2.2 Merging, cropping and masking\r\nSince there are four hdf files in each year for our AOI, we can first merge the four SpatRaster files into one file per year. We’ll use 2010 as an example. We can filter to only include our layer of interest - percent of tree cover - from each hdf file, which can be done by subsetting the output using [[1]] (using 1 because percent tree cover is the first layer in each file).\r\n\r\n\r\n\r\nBefore we merge these SpatRster objects, it is often a good practice to check their origins and resolutions. merge requires origin and resolution to be the same across objects.\r\n\r\n\r\n\r\n\r\n\r\n\r\nWe see that origins of these files are slightly different, but all are close to (0, 0). We do not need to worry about these slight differences, as merge will handle them automatically.\r\n\r\n\r\n\r\nNote: cells with 200% represent water and rivers.\r\nWe are now ready to crop and mask the raster file to match our AOI. This tutorial explains the difference between cropping and masking.\r\nTo crop a raster file according to vector data boundaries (eg, our aoi object representing Odisha districts), we first align the coordinate reference systems of our raster file and vector file. Then, use crop(raster data, vector data). To mask, use mask(raster data, vector data). Note that for terra::mask(), the second argument needs to be SpatVector. terra does not support sf objects yet, so we use vect(aoi) to convert our sf object aoi to a SpatVector.\r\n\r\n\r\n\r\nTo plot our new raster file, we use:\r\n\r\n\r\n\r\n2.3 Extracting values and computing statistics\r\nAfter we have cropped and masked the raster file to our AOI, we can extract values for each county in the state of Odisha.\r\n\r\n\r\n\r\nThe values extracted by terra::extract are stored in a data frame. Note that the ID corresponds to the row number of your vector file (i.e. object aoi in our case). We can then compute statistics based on this data frame. Here we compute several statistics describing the percent of forest cover for each county. Note that cells with 200% represent water and river and should be excluded from calculation.\r\n\r\n\r\n\r\n2.4 Storing and exporting results\r\nWith terra you can easily write shape files and several formats of raster files. The main function for writing vector data is writeVector(), while for writing raster data we use writeRaster(). For details, you can refer to this page and the documentation of terra.\r\n3. A practical example\r\nWe will replicate some main results in the paper. To access the full replication data and code, check this github repo. We are going to replicate Table 3 in the paper.\r\nThe research question is whether newly constructed rural roads impact local deforestation. The authors explored this question using two empirical strategies: fuzzy RD and difference-in-difference. In the following sections, we implement the difference-in-difference method and replicate the regression results.\r\nIn order to run fixed effects models, we will need the fixest package. This tutorial is a good reference for introducing fixest functions.\r\nData for this exercise was processed and stored in pmgsy_trees_rural_panel.csv, which you can find the through the link to the CSV data in the github repo. Each row of the data frame presents a village in a specific year.\r\n\r\n\r\n\r\nThe paper estimated the following equation:\r\n\\[\r\nForest_{vdt} = β_{1}Award_{vdt} + β_{2}Complete_{vdt} + α_{v} + γ_{dt} + X_{v}⋅V_{t} + η_{vdt}\r\n\\]\r\nwhere \\(Forest_{vdt}\\) is forest cover of village \\(v\\) in district \\(d\\) in year \\(t\\). \\(Award_{vdt}\\) is a dummy variable which takes one during the period when the new road is awarded to the village but has not been built. \\(Complete_{vdt}\\) is also a dummy variable which takes one for all years following the completion of a new road to village \\(v\\). \\(α_{v}\\) are village fixed effects, while \\(γ_{dt}\\) are the district-year fixed effects. \\(X_{v}\\) controls some baseline characteristics (e.g. forest cover in 2000, total population) and is interacted with year fixed effects \\(V_{t}\\).\r\nThere is one more step before we run the regressions. In Stata, which the authors used for their regression, reghdfe removed singleton groups automatically. However, the fixest package currently doesn’t possess this functionality, so for now, we will manually remove these observations.\r\n\r\n\r\n\r\nFinally, we can run our regressions. Following the authors, we test the effect of being awarded a new road and receiving the road on the log forest cover as well as on the average forest cover.\r\n\r\n\r\n\r\nOur results align with the authors’ findings presented in Table 3 which show that being awarded a road has a negative impact on forest cover (approximately 0.5% loss in the construction period between being awarded a road and its completion), but after the road is constructed, forest cover appears to return. This could incorrectly be interpreted as a positive effect of roads on tree cover if the award term is left out. This determination that rural roads have no effect on forest loss, in combination with the authors’ additional findings of substantial forest loss due to highway construction, have important policy implications for governments considering similar infrastructure expansion. The use of VCF data in this study enabled significant insights, and the potential use cases for VCF data remain numerous.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-10-15T22:22:24+08:00",
    "input_file": {}
  }
]
